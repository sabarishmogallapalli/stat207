{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 207 Lab Assignment 8 - Individual Part - [23 points]\n",
    "\n",
    "\n",
    "# <u>Case Study</u>: Predicting Coffee Flavor *for New Coffee Brands*\n",
    "\n",
    "\n",
    "\n",
    "### Coffee Dataset Information\n",
    "\n",
    "In this individual assignment we will return to the `coffee.csv` dataset. Information about the variables in this dataset can be found here: https://corgis-edu.github.io/corgis/csv/coffee/\n",
    "\n",
    "\n",
    "### Research Goals\n",
    "\n",
    "In this individual assignment we would ideally like to pursue multiple research goals.\n",
    "\n",
    "#### Main Research Goal\n",
    "\n",
    "Our main research goal will be to create a predictive model that effectively predicts the `Flavor` of *new coffee brands*.\n",
    "\n",
    "\n",
    "#### Secondary Research Goals\n",
    "\n",
    "Ideally, the predictive model that we select will also be able to accurately reflect the relationship between the explanatory variables and the response variable `Flavor`.\n",
    "\n",
    "\n",
    "## Points\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "<table style=\"border: none;border-collapse: collapse;width:102pt;\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;width:51pt;\">Problem</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:general;vertical-align:bottom;border:.5pt solid windowtext;border-left:none;width:51pt;\">Points</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.5</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.6.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.6.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.7</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">2.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">2.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.5.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.5.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.6</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.5.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.5.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.5.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4.5.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Tutorial</u>: Iteratively Updating a List of Lists\n",
    "\n",
    "You may need this tutorial in this assignment.\n",
    "\n",
    "Suppose we wanted to iterate through a range of `i` values going from 0, 0.5, 1, 1.5, ..., 19.5.\n",
    "\n",
    "For each of these `i` values we wanted to add a sublist `[i, 3*i]` to a list of lists. \n",
    "\n",
    "We can do so as follows using the code below.\n",
    "1. The **np.arange(a, b, c)** function creates a list of values going from `a` to `b-c`, using a step size of `c`.\n",
    "2. The **.append()** function adds the given value in the parantheses to the corresponding list that the **.append()** function corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0],\n",
       " [0.5, 1.5],\n",
       " [1.0, 3.0],\n",
       " [1.5, 4.5],\n",
       " [2.0, 6.0],\n",
       " [2.5, 7.5],\n",
       " [3.0, 9.0],\n",
       " [3.5, 10.5],\n",
       " [4.0, 12.0],\n",
       " [4.5, 13.5],\n",
       " [5.0, 15.0],\n",
       " [5.5, 16.5],\n",
       " [6.0, 18.0],\n",
       " [6.5, 19.5],\n",
       " [7.0, 21.0],\n",
       " [7.5, 22.5],\n",
       " [8.0, 24.0],\n",
       " [8.5, 25.5],\n",
       " [9.0, 27.0],\n",
       " [9.5, 28.5],\n",
       " [10.0, 30.0],\n",
       " [10.5, 31.5],\n",
       " [11.0, 33.0],\n",
       " [11.5, 34.5],\n",
       " [12.0, 36.0],\n",
       " [12.5, 37.5],\n",
       " [13.0, 39.0],\n",
       " [13.5, 40.5],\n",
       " [14.0, 42.0],\n",
       " [14.5, 43.5],\n",
       " [15.0, 45.0],\n",
       " [15.5, 46.5],\n",
       " [16.0, 48.0],\n",
       " [16.5, 49.5],\n",
       " [17.0, 51.0],\n",
       " [17.5, 52.5],\n",
       " [18.0, 54.0],\n",
       " [18.5, 55.5],\n",
       " [19.0, 57.0],\n",
       " [19.5, 58.5]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list=[]\n",
    "for i in np.arange(0,20,0.5):\n",
    "    temp_list.append([i, 3*i])\n",
    "temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this list of lists into a dataframe with the column names `a` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.5</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.5</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.5</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.5</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.5</td>\n",
       "      <td>28.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.5</td>\n",
       "      <td>31.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.5</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.5</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.5</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.5</td>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15.5</td>\n",
       "      <td>46.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16.5</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>17.5</td>\n",
       "      <td>52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18.5</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19.5</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a     b\n",
       "0    0.0   0.0\n",
       "1    0.5   1.5\n",
       "2    1.0   3.0\n",
       "3    1.5   4.5\n",
       "4    2.0   6.0\n",
       "5    2.5   7.5\n",
       "6    3.0   9.0\n",
       "7    3.5  10.5\n",
       "8    4.0  12.0\n",
       "9    4.5  13.5\n",
       "10   5.0  15.0\n",
       "11   5.5  16.5\n",
       "12   6.0  18.0\n",
       "13   6.5  19.5\n",
       "14   7.0  21.0\n",
       "15   7.5  22.5\n",
       "16   8.0  24.0\n",
       "17   8.5  25.5\n",
       "18   9.0  27.0\n",
       "19   9.5  28.5\n",
       "20  10.0  30.0\n",
       "21  10.5  31.5\n",
       "22  11.0  33.0\n",
       "23  11.5  34.5\n",
       "24  12.0  36.0\n",
       "25  12.5  37.5\n",
       "26  13.0  39.0\n",
       "27  13.5  40.5\n",
       "28  14.0  42.0\n",
       "29  14.5  43.5\n",
       "30  15.0  45.0\n",
       "31  15.5  46.5\n",
       "32  16.0  48.0\n",
       "33  16.5  49.5\n",
       "34  17.0  51.0\n",
       "35  17.5  52.5\n",
       "36  18.0  54.0\n",
       "37  18.5  55.5\n",
       "38  19.0  57.0\n",
       "39  19.5  58.5"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(temp_list, columns=['a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Coffee Dataset\n",
    "\n",
    "### 1.1. Reading the csv\n",
    "\n",
    "1. Read the `coffee.csv` into a dataframe. The strings that are used to represent missing values in this csv file are represented with 'nan'. Luckily, 'nan' is one of the string values that the **pd.read_csv()** function is automatically programmed to detect as a missing value and thus convert into a NaN type object.\n",
    "2. Show the first 5 rows.\n",
    "3. Show how many rows this dataframe has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Country</th>\n",
       "      <th>Location_Region</th>\n",
       "      <th>Location_Altitude_Min</th>\n",
       "      <th>Location_Altitude_Max</th>\n",
       "      <th>Location_Altitude_Average</th>\n",
       "      <th>Year</th>\n",
       "      <th>Data_Owner</th>\n",
       "      <th>Data_Type_Species</th>\n",
       "      <th>Data_Type_Variety</th>\n",
       "      <th>Data_Type_Processing method</th>\n",
       "      <th>...</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "      <th>Data_Scores_Total</th>\n",
       "      <th>Data_Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>kona</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>kona pacific farmers cooperative</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.08</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.25</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>sul de minas - carmo de minas</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>jacques pereira carneiro</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>Yellow Bourbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>86.17</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>sul de minas - carmo de minas</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>jacques pereira carneiro</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>Yellow Bourbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>86.17</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>sidamo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>ethiopia commodity exchange</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>85.08</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>sidamo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>ethiopia commodity exchange</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.58</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>83.83</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location_Country                Location_Region  Location_Altitude_Min  \\\n",
       "0    United States                           kona                      0   \n",
       "1           Brazil  sul de minas - carmo de minas                     12   \n",
       "2           Brazil  sul de minas - carmo de minas                     12   \n",
       "3         Ethiopia                         sidamo                      0   \n",
       "4         Ethiopia                         sidamo                      0   \n",
       "\n",
       "   Location_Altitude_Max  Location_Altitude_Average  Year  \\\n",
       "0                      0                          0  2010   \n",
       "1                     12                         12  2010   \n",
       "2                     12                         12  2010   \n",
       "3                      0                          0  2010   \n",
       "4                      0                          0  2010   \n",
       "\n",
       "                         Data_Owner Data_Type_Species Data_Type_Variety  \\\n",
       "0  kona pacific farmers cooperative           Arabica               NaN   \n",
       "1          jacques pereira carneiro           Arabica    Yellow Bourbon   \n",
       "2          jacques pereira carneiro           Arabica    Yellow Bourbon   \n",
       "3       ethiopia commodity exchange           Arabica               NaN   \n",
       "4       ethiopia commodity exchange           Arabica               NaN   \n",
       "\n",
       "  Data_Type_Processing method  ...  Data_Scores_Flavor  \\\n",
       "0                         NaN  ...                8.42   \n",
       "1                         NaN  ...                7.92   \n",
       "2                         NaN  ...                7.92   \n",
       "3                         NaN  ...                8.00   \n",
       "4                         NaN  ...                7.83   \n",
       "\n",
       "   Data_Scores_Aftertaste  Data_Scores_Acidity  Data_Scores_Body  \\\n",
       "0                    8.08                 7.75              7.67   \n",
       "1                    7.92                 7.75              8.33   \n",
       "2                    8.00                 7.75              7.92   \n",
       "3                    7.83                 8.00              7.92   \n",
       "4                    7.58                 8.00              7.83   \n",
       "\n",
       "   Data_Scores_Balance  Data_Scores_Uniformity  Data_Scores_Sweetness  \\\n",
       "0                 7.83                    10.0                   10.0   \n",
       "1                 8.00                    10.0                   10.0   \n",
       "2                 8.00                    10.0                   10.0   \n",
       "3                 7.83                    10.0                   10.0   \n",
       "4                 7.50                    10.0                   10.0   \n",
       "\n",
       "   Data_Scores_Moisture  Data_Scores_Total  Data_Color  \n",
       "0                  0.00              86.25     Unknown  \n",
       "1                  0.08              86.17     Unknown  \n",
       "2                  0.01              86.17     Unknown  \n",
       "3                  0.00              85.08     Unknown  \n",
       "4                  0.10              83.83     Unknown  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df = pd.read_csv('coffee.csv')\n",
    "coffee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coffee dataset has 989 rows.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The coffee dataset has {coffee_df.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dropping NaN Values\n",
    "\n",
    "We only intend to use the following variables in this dataframe:\n",
    "* `Data_Scores_Aroma`\n",
    "* `Data_Scores_Flavor`\n",
    "* `Data_Scores_Aftertaste`\n",
    "* `Data_Scores_Acidity`\n",
    "* `Data_Scores_Body`\n",
    "* `Data_Scores_Balance`\n",
    "* `Data_Scores_Uniformity`\n",
    "* `Data_Scores_Sweetness`\n",
    "* `Data_Scores_Moisture`.\n",
    "\n",
    "1. Create a dataframe with just these variables.\n",
    "2. Then drop all rows from this dataframe that have a NaN value.\n",
    "3. How many rows did you drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.25</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.08</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.42</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.67</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.58</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>8.67</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>8.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
       "0                 8.25                8.42                    8.08   \n",
       "1                 8.17                7.92                    7.92   \n",
       "2                 8.42                7.92                    8.00   \n",
       "3                 7.67                8.00                    7.83   \n",
       "4                 7.58                7.83                    7.58   \n",
       "..                 ...                 ...                     ...   \n",
       "984               7.58                7.67                    7.42   \n",
       "985               0.00                0.00                    0.00   \n",
       "986               8.00                7.75                    7.92   \n",
       "987               7.67                7.75                    7.83   \n",
       "988               7.50                7.42                    7.08   \n",
       "\n",
       "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Balance  \\\n",
       "0                   7.75              7.67                 7.83   \n",
       "1                   7.75              8.33                 8.00   \n",
       "2                   7.75              7.92                 8.00   \n",
       "3                   8.00              7.92                 7.83   \n",
       "4                   8.00              7.83                 7.50   \n",
       "..                   ...               ...                  ...   \n",
       "984                 7.42              7.67                 7.67   \n",
       "985                 0.00              0.00                 0.00   \n",
       "986                 8.00              7.92                 7.92   \n",
       "987                 7.67              7.92                 7.83   \n",
       "988                 7.42              7.50                 7.33   \n",
       "\n",
       "     Data_Scores_Uniformity  Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "0                     10.00                  10.00                  0.00  \n",
       "1                     10.00                  10.00                  0.08  \n",
       "2                     10.00                  10.00                  0.01  \n",
       "3                     10.00                  10.00                  0.00  \n",
       "4                     10.00                  10.00                  0.10  \n",
       "..                      ...                    ...                   ...  \n",
       "984                    8.67                   8.67                  0.10  \n",
       "985                    0.00                   0.00                  0.12  \n",
       "986                   10.00                   8.00                  0.00  \n",
       "987                   10.00                   7.92                  0.10  \n",
       "988                   10.00                  10.00                  0.11  \n",
       "\n",
       "[989 rows x 9 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df = coffee_df[['Data_Scores_Aroma','Data_Scores_Flavor','Data_Scores_Aftertaste','Data_Scores_Acidity','Data_Scores_Body','Data_Scores_Balance','Data_Scores_Uniformity','Data_Scores_Sweetness','Data_Scores_Moisture']]\n",
    "nine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.25</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.08</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.42</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.67</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.58</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>8.67</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>8.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
       "0                 8.25                8.42                    8.08   \n",
       "1                 8.17                7.92                    7.92   \n",
       "2                 8.42                7.92                    8.00   \n",
       "3                 7.67                8.00                    7.83   \n",
       "4                 7.58                7.83                    7.58   \n",
       "..                 ...                 ...                     ...   \n",
       "984               7.58                7.67                    7.42   \n",
       "985               0.00                0.00                    0.00   \n",
       "986               8.00                7.75                    7.92   \n",
       "987               7.67                7.75                    7.83   \n",
       "988               7.50                7.42                    7.08   \n",
       "\n",
       "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Balance  \\\n",
       "0                   7.75              7.67                 7.83   \n",
       "1                   7.75              8.33                 8.00   \n",
       "2                   7.75              7.92                 8.00   \n",
       "3                   8.00              7.92                 7.83   \n",
       "4                   8.00              7.83                 7.50   \n",
       "..                   ...               ...                  ...   \n",
       "984                 7.42              7.67                 7.67   \n",
       "985                 0.00              0.00                 0.00   \n",
       "986                 8.00              7.92                 7.92   \n",
       "987                 7.67              7.92                 7.83   \n",
       "988                 7.42              7.50                 7.33   \n",
       "\n",
       "     Data_Scores_Uniformity  Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "0                     10.00                  10.00                  0.00  \n",
       "1                     10.00                  10.00                  0.08  \n",
       "2                     10.00                  10.00                  0.01  \n",
       "3                     10.00                  10.00                  0.00  \n",
       "4                     10.00                  10.00                  0.10  \n",
       "..                      ...                    ...                   ...  \n",
       "984                    8.67                   8.67                  0.10  \n",
       "985                    0.00                   0.00                  0.12  \n",
       "986                   10.00                   8.00                  0.00  \n",
       "987                   10.00                   7.92                  0.10  \n",
       "988                   10.00                  10.00                  0.11  \n",
       "\n",
       "[989 rows x 9 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.25, 8.17, 8.42, 7.67, 7.58, 7.5 , 7.25, 7.42, 6.92, 8.5 , 8.33,\n",
       "       8.  , 7.75, 7.33, 7.08, 8.08, 7.83, 7.92, 7.  , 7.17, 6.83, 6.67,\n",
       "       6.75, 6.5 , 8.58, 8.67, 8.75, 6.33, 5.08, 7.81, 0.  ])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df[\"Data_Scores_Aroma\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.42, 7.92, 8.  , 7.83, 7.58, 7.25, 7.42, 6.75, 8.5 , 8.17, 7.75,\n",
       "       7.5 , 7.67, 7.33, 7.  , 8.25, 8.33, 8.08, 7.17, 7.08, 6.67, 6.83,\n",
       "       6.92, 6.5 , 6.08, 6.17, 6.58, 6.42, 6.33, 8.83, 8.67, 8.58, 7.88,\n",
       "       0.  ])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df[\"Data_Scores_Flavor\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.08, 7.92, 8.  , 7.83, 7.58, 7.42, 7.5 , 7.25, 7.08, 7.75, 7.67,\n",
       "       7.33, 7.17, 6.5 , 8.33, 8.17, 7.  , 6.92, 6.83, 6.33, 6.67, 6.75,\n",
       "       6.17, 6.58, 6.42, 6.25, 8.42, 8.67, 8.5 , 8.25, 8.58, 7.56, 0.  ])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df[\"Data_Scores_Aftertaste\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.75, 8.  , 7.67, 7.58, 7.33, 7.92, 7.17, 7.5 , 7.25, 6.08, 8.5 ,\n",
       "       8.25, 8.08, 8.17, 8.33, 7.83, 8.42, 7.42, 6.75, 7.  , 7.08, 6.83,\n",
       "       6.92, 6.67, 8.75, 8.58, 6.5 , 5.25, 6.25, 0.  ])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df[\"Data_Scores_Acidity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.67, 8.33, 7.92, 7.83, 7.5 , 7.75, 7.33, 8.  , 7.58, 7.42, 7.17,\n",
       "       8.25, 8.08, 7.25, 7.  , 7.08, 8.17, 6.92, 6.75, 6.83, 6.67, 8.5 ,\n",
       "       8.42, 6.33, 6.5 , 5.25, 6.42, 5.08, 5.17, 7.63, 0.  ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df[\"Data_Scores_Body\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.83, 8.  , 7.5 , 7.58, 6.67, 7.75, 7.67, 7.42, 7.25, 7.33, 6.33,\n",
       "       8.25, 8.17, 7.92, 8.08, 6.83, 7.08, 7.17, 7.  , 6.92, 6.75, 6.58,\n",
       "       6.5 , 8.33, 8.58, 8.42, 8.5 , 6.17, 6.42, 6.08, 5.25, 0.  ])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df[\"Data_Scores_Balance\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.  ,  9.33,  8.67,  6.67,  8.  ,  7.33,  6.  ,  0.  ])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df[\"Data_Scores_Uniformity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.  ,  8.67,  9.33,  6.67,  8.  ,  6.  ,  1.33,  7.75,  7.58,\n",
       "        7.83,  7.67,  7.42,  7.08,  7.5 ,  7.92,  8.42,  0.  ])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df[\"Data_Scores_Sweetness\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.08, 0.01, 0.1 , 0.05, 0.12, 0.11, 0.02, 0.06, 0.28, 0.2 ,\n",
       "       0.13, 0.09, 0.14, 0.15, 0.16, 0.17, 0.07])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df[\"Data_Scores_Moisture\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Dropping a Large Outlier\n",
    "\n",
    "This dataset has a prominent outlier with an `Aroma` rating that is equal to 0. Drop this observation from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
       "985                0.0                 0.0                     0.0   \n",
       "\n",
       "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Balance  \\\n",
       "985                  0.0               0.0                  0.0   \n",
       "\n",
       "     Data_Scores_Uniformity  Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "985                     0.0                    0.0                  0.12  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aroma_drop = nine_df.loc[nine_df['Data_Scores_Aroma'] == 0]\n",
    "aroma_drop\n",
    "#row 985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Flavor</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.25</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.08</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.42</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.67</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.58</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.92</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.92</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>8.67</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>8.00</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>7.50</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.33</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Flavor  Data_Scores_Aftertaste  \\\n",
       "0                 8.25                8.42                    8.08   \n",
       "1                 8.17                7.92                    7.92   \n",
       "2                 8.42                7.92                    8.00   \n",
       "3                 7.67                8.00                    7.83   \n",
       "4                 7.58                7.83                    7.58   \n",
       "..                 ...                 ...                     ...   \n",
       "983               7.58                7.00                    6.75   \n",
       "984               7.58                7.67                    7.42   \n",
       "986               8.00                7.75                    7.92   \n",
       "987               7.67                7.75                    7.83   \n",
       "988               7.50                7.42                    7.08   \n",
       "\n",
       "     Data_Scores_Acidity  Data_Scores_Body  Data_Scores_Balance  \\\n",
       "0                   7.75              7.67                 7.83   \n",
       "1                   7.75              8.33                 8.00   \n",
       "2                   7.75              7.92                 8.00   \n",
       "3                   8.00              7.92                 7.83   \n",
       "4                   8.00              7.83                 7.50   \n",
       "..                   ...               ...                  ...   \n",
       "983                 6.92              7.00                 6.92   \n",
       "984                 7.42              7.67                 7.67   \n",
       "986                 8.00              7.92                 7.92   \n",
       "987                 7.67              7.92                 7.83   \n",
       "988                 7.42              7.50                 7.33   \n",
       "\n",
       "     Data_Scores_Uniformity  Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "0                     10.00                  10.00                  0.00  \n",
       "1                     10.00                  10.00                  0.08  \n",
       "2                     10.00                  10.00                  0.01  \n",
       "3                     10.00                  10.00                  0.00  \n",
       "4                     10.00                  10.00                  0.10  \n",
       "..                      ...                    ...                   ...  \n",
       "983                   10.00                  10.00                  0.11  \n",
       "984                    8.67                   8.67                  0.10  \n",
       "986                   10.00                   8.00                  0.00  \n",
       "987                   10.00                   7.92                  0.10  \n",
       "988                   10.00                  10.00                  0.11  \n",
       "\n",
       "[988 rows x 9 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine_df.drop(985)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Training and Test Datasets\n",
    "\n",
    "We intend to build linear regression models that will predict the `Flavor` of *new coffee brands* using some of the following explanatory variables.\n",
    "\n",
    "* `Data_Scores_Aroma`\n",
    "* `Data_Scores_Aftertaste`\n",
    "* `Data_Scores_Acidity`\n",
    "* `Data_Scores_Body`\n",
    "* `Data_Scores_Balance`\n",
    "* `Data_Scores_Uniformity`\n",
    "* `Data_Scores_Sweetness`\n",
    "* `Data_Scores_Moisture`\n",
    "\n",
    "\n",
    "Using some combination of these explanatory variables, we'd like to build and select a linear regression model which we can infer might perform well when it comes to predicting the `Flavor` of *new coffee brands*. Thus, let's create a training and a test dataset from our cleaned dataframe from 1.3.\n",
    "\n",
    "Use a random state of `437` to do this. Your training dataset should be 80% of observations from your cleaned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test,df_train = train_test_split(nine_df,test_size = 0.2,random_state = 437)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Features Matrices and Target Arrays\n",
    "\n",
    "Use your training dataset and test dataset to create the following.\n",
    "* Training features matrix\n",
    "* Training target array\n",
    "* Test features matrix\n",
    "* Test target array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>7.83</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.08</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>7.83</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>7.17</td>\n",
       "      <td>6.58</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.25</td>\n",
       "      <td>6.58</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.75</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.75</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Aftertaste  Data_Scores_Acidity  \\\n",
       "726               7.83                    7.83                 7.92   \n",
       "655               7.83                    7.08                 7.08   \n",
       "333               7.17                    6.58                 7.00   \n",
       "83                7.67                    7.67                 7.75   \n",
       "384               7.67                    7.67                 7.75   \n",
       "\n",
       "     Data_Scores_Body  Data_Scores_Balance  Data_Scores_Uniformity  \\\n",
       "726              7.83                 8.08                   10.00   \n",
       "655              7.33                 7.50                   10.00   \n",
       "333              7.25                 6.58                    9.33   \n",
       "83               7.67                 7.75                   10.00   \n",
       "384              7.67                 7.75                   10.00   \n",
       "\n",
       "     Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "726                   10.0                  0.12  \n",
       "655                   10.0                  0.12  \n",
       "333                   10.0                  0.13  \n",
       "83                    10.0                  0.11  \n",
       "384                   10.0                  0.11  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training features matrix\n",
    "training_explanatory = df_train.drop(['Data_Scores_Flavor'],axis=1)\n",
    "training_explanatory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726    8.00\n",
       "655    7.33\n",
       "333    6.58\n",
       "83     7.75\n",
       "384    7.83\n",
       "Name: Data_Scores_Flavor, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training target array\n",
    "training_response = df_train['Data_Scores_Flavor']\n",
    "training_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>8.08</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>7.33</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.92</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>7.58</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.58</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7.83</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Scores_Aroma  Data_Scores_Aftertaste  Data_Scores_Acidity  \\\n",
       "936               8.08                    7.67                 7.58   \n",
       "889               7.33                    7.50                 7.33   \n",
       "825               7.92                    7.92                 8.00   \n",
       "409               7.58                    7.50                 7.50   \n",
       "71                7.83                    7.75                 8.00   \n",
       "\n",
       "     Data_Scores_Body  Data_Scores_Balance  Data_Scores_Uniformity  \\\n",
       "936              7.25                 7.67                    10.0   \n",
       "889              7.50                 7.50                    10.0   \n",
       "825              7.83                 7.92                    10.0   \n",
       "409              7.58                 7.58                    10.0   \n",
       "71               7.50                 7.75                    10.0   \n",
       "\n",
       "     Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "936                  10.00                  0.11  \n",
       "889                  10.00                  0.11  \n",
       "825                   7.83                  0.00  \n",
       "409                  10.00                  0.12  \n",
       "71                   10.00                  0.11  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test features matrix\n",
    "test_explanatory = df_test.drop(['Data_Scores_Flavor'],axis=1)\n",
    "test_explanatory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936    7.67\n",
       "889    7.50\n",
       "825    7.83\n",
       "409    7.75\n",
       "71     7.83\n",
       "Name: Data_Scores_Flavor, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test target array\n",
    "test_response = df_test['Data_Scores_Flavor']\n",
    "test_response.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Scaling the Features Matrices\n",
    "\n",
    "We'd like to be able to compare the magnitudes of our slopes in our linear regression models to try to infer the corresponding explanatory variable's importance when it comes to predicting coffee flavor. \n",
    "\n",
    "So let's z-score scale our training features matrix as well as our test features matrix.\n",
    "\n",
    "#### 1.6.1. Scaling the Training Features Matrix\n",
    "\n",
    "Z-score scale each of the values in your TRAINING features matrix using the corresponding TRAINING data column means and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data_Scores_Aroma         float64\n",
       "Data_Scores_Aftertaste    float64\n",
       "Data_Scores_Acidity       float64\n",
       "Data_Scores_Body          float64\n",
       "Data_Scores_Balance       float64\n",
       "Data_Scores_Uniformity    float64\n",
       "Data_Scores_Sweetness     float64\n",
       "Data_Scores_Moisture      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_explanatory.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.797478</td>\n",
       "      <td>1.095497</td>\n",
       "      <td>1.082302</td>\n",
       "      <td>0.928941</td>\n",
       "      <td>1.567666</td>\n",
       "      <td>0.396847</td>\n",
       "      <td>0.313055</td>\n",
       "      <td>0.651217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.797478</td>\n",
       "      <td>-0.840033</td>\n",
       "      <td>-1.409854</td>\n",
       "      <td>-0.683634</td>\n",
       "      <td>-0.020187</td>\n",
       "      <td>0.396847</td>\n",
       "      <td>0.313055</td>\n",
       "      <td>0.651217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.392822</td>\n",
       "      <td>-2.130387</td>\n",
       "      <td>-1.647202</td>\n",
       "      <td>-0.941646</td>\n",
       "      <td>-2.538851</td>\n",
       "      <td>-0.763007</td>\n",
       "      <td>0.313055</td>\n",
       "      <td>0.868290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266497</td>\n",
       "      <td>0.682584</td>\n",
       "      <td>0.577937</td>\n",
       "      <td>0.412917</td>\n",
       "      <td>0.664233</td>\n",
       "      <td>0.396847</td>\n",
       "      <td>0.313055</td>\n",
       "      <td>0.434145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266497</td>\n",
       "      <td>0.682584</td>\n",
       "      <td>0.577937</td>\n",
       "      <td>0.412917</td>\n",
       "      <td>0.664233</td>\n",
       "      <td>0.396847</td>\n",
       "      <td>0.313055</td>\n",
       "      <td>0.434145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data_Scores_Aroma  Data_Scores_Aftertaste  Data_Scores_Acidity  \\\n",
       "0           0.797478                1.095497             1.082302   \n",
       "1           0.797478               -0.840033            -1.409854   \n",
       "2          -1.392822               -2.130387            -1.647202   \n",
       "3           0.266497                0.682584             0.577937   \n",
       "4           0.266497                0.682584             0.577937   \n",
       "\n",
       "   Data_Scores_Body  Data_Scores_Balance  Data_Scores_Uniformity  \\\n",
       "0          0.928941             1.567666                0.396847   \n",
       "1         -0.683634            -0.020187                0.396847   \n",
       "2         -0.941646            -2.538851               -0.763007   \n",
       "3          0.412917             0.664233                0.396847   \n",
       "4          0.412917             0.664233                0.396847   \n",
       "\n",
       "   Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "0               0.313055              0.651217  \n",
       "1               0.313055              0.651217  \n",
       "2               0.313055              0.868290  \n",
       "3               0.313055              0.434145  \n",
       "4               0.313055              0.434145  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_training = StandardScaler()\n",
    "\n",
    "scaled_explvars = scaler_training.fit_transform(training_explanatory)\n",
    "\n",
    "training_explanatory = pd.DataFrame(scaled_explvars,columns = training_explanatory.columns)\n",
    "training_explanatory.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.2. Scaling the Test Features Matrix\n",
    "\n",
    "Z-score scale each of the values in your TEST features matrix using the corresponding TRAINING data column means and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.226521</td>\n",
       "      <td>0.661617</td>\n",
       "      <td>0.106941</td>\n",
       "      <td>-0.605424</td>\n",
       "      <td>0.390943</td>\n",
       "      <td>0.272813</td>\n",
       "      <td>0.229277</td>\n",
       "      <td>0.341881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.572282</td>\n",
       "      <td>0.269775</td>\n",
       "      <td>-0.498142</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.272813</td>\n",
       "      <td>0.229277</td>\n",
       "      <td>0.341881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.842777</td>\n",
       "      <td>1.237855</td>\n",
       "      <td>1.123481</td>\n",
       "      <td>0.814018</td>\n",
       "      <td>0.961109</td>\n",
       "      <td>0.272813</td>\n",
       "      <td>-2.896840</td>\n",
       "      <td>-2.145331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027319</td>\n",
       "      <td>0.269775</td>\n",
       "      <td>-0.086685</td>\n",
       "      <td>0.202190</td>\n",
       "      <td>0.185683</td>\n",
       "      <td>0.272813</td>\n",
       "      <td>0.229277</td>\n",
       "      <td>0.567991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.626920</td>\n",
       "      <td>0.846013</td>\n",
       "      <td>1.123481</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.573396</td>\n",
       "      <td>0.272813</td>\n",
       "      <td>0.229277</td>\n",
       "      <td>0.341881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data_Scores_Aroma  Data_Scores_Aftertaste  Data_Scores_Acidity  \\\n",
       "0           1.226521                0.661617             0.106941   \n",
       "1          -0.572282                0.269775            -0.498142   \n",
       "2           0.842777                1.237855             1.123481   \n",
       "3           0.027319                0.269775            -0.086685   \n",
       "4           0.626920                0.846013             1.123481   \n",
       "\n",
       "   Data_Scores_Body  Data_Scores_Balance  Data_Scores_Uniformity  \\\n",
       "0         -0.605424             0.390943                0.272813   \n",
       "1          0.006404             0.003229                0.272813   \n",
       "2          0.814018             0.961109                0.272813   \n",
       "3          0.202190             0.185683                0.272813   \n",
       "4          0.006404             0.573396                0.272813   \n",
       "\n",
       "   Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "0               0.229277              0.341881  \n",
       "1               0.229277              0.341881  \n",
       "2              -2.896840             -2.145331  \n",
       "3               0.229277              0.567991  \n",
       "4               0.229277              0.341881  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_explvars = scaler_training.fit_transform(test_explanatory)\n",
    "\n",
    "test_explanatory = pd.DataFrame(scaled_explvars,columns = test_explanatory.columns)\n",
    "test_explanatory.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Multicollinearity\n",
    "\n",
    "Does your training dataset have an issue with multicollinearity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aroma</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.743627</td>\n",
       "      <td>0.644793</td>\n",
       "      <td>0.614419</td>\n",
       "      <td>0.692192</td>\n",
       "      <td>0.252328</td>\n",
       "      <td>0.074047</td>\n",
       "      <td>-0.148588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Aftertaste</th>\n",
       "      <td>0.743627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772221</td>\n",
       "      <td>0.717893</td>\n",
       "      <td>0.860191</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.250585</td>\n",
       "      <td>-0.223684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Acidity</th>\n",
       "      <td>0.644793</td>\n",
       "      <td>0.772221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.654333</td>\n",
       "      <td>0.758786</td>\n",
       "      <td>0.305512</td>\n",
       "      <td>0.323370</td>\n",
       "      <td>-0.166047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Body</th>\n",
       "      <td>0.614419</td>\n",
       "      <td>0.717893</td>\n",
       "      <td>0.654333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.752955</td>\n",
       "      <td>0.241606</td>\n",
       "      <td>0.151394</td>\n",
       "      <td>-0.224135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Balance</th>\n",
       "      <td>0.692192</td>\n",
       "      <td>0.860191</td>\n",
       "      <td>0.758786</td>\n",
       "      <td>0.752955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.441438</td>\n",
       "      <td>0.284841</td>\n",
       "      <td>-0.235669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Uniformity</th>\n",
       "      <td>0.252328</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.305512</td>\n",
       "      <td>0.241606</td>\n",
       "      <td>0.441438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434928</td>\n",
       "      <td>-0.057012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Sweetness</th>\n",
       "      <td>0.074047</td>\n",
       "      <td>0.250585</td>\n",
       "      <td>0.323370</td>\n",
       "      <td>0.151394</td>\n",
       "      <td>0.284841</td>\n",
       "      <td>0.434928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Scores_Moisture</th>\n",
       "      <td>-0.148588</td>\n",
       "      <td>-0.223684</td>\n",
       "      <td>-0.166047</td>\n",
       "      <td>-0.224135</td>\n",
       "      <td>-0.235669</td>\n",
       "      <td>-0.057012</td>\n",
       "      <td>-0.011637</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Data_Scores_Aroma  Data_Scores_Aftertaste  \\\n",
       "Data_Scores_Aroma                1.000000                0.743627   \n",
       "Data_Scores_Aftertaste           0.743627                1.000000   \n",
       "Data_Scores_Acidity              0.644793                0.772221   \n",
       "Data_Scores_Body                 0.614419                0.717893   \n",
       "Data_Scores_Balance              0.692192                0.860191   \n",
       "Data_Scores_Uniformity           0.252328                0.398230   \n",
       "Data_Scores_Sweetness            0.074047                0.250585   \n",
       "Data_Scores_Moisture            -0.148588               -0.223684   \n",
       "\n",
       "                        Data_Scores_Acidity  Data_Scores_Body  \\\n",
       "Data_Scores_Aroma                  0.644793          0.614419   \n",
       "Data_Scores_Aftertaste             0.772221          0.717893   \n",
       "Data_Scores_Acidity                1.000000          0.654333   \n",
       "Data_Scores_Body                   0.654333          1.000000   \n",
       "Data_Scores_Balance                0.758786          0.752955   \n",
       "Data_Scores_Uniformity             0.305512          0.241606   \n",
       "Data_Scores_Sweetness              0.323370          0.151394   \n",
       "Data_Scores_Moisture              -0.166047         -0.224135   \n",
       "\n",
       "                        Data_Scores_Balance  Data_Scores_Uniformity  \\\n",
       "Data_Scores_Aroma                  0.692192                0.252328   \n",
       "Data_Scores_Aftertaste             0.860191                0.398230   \n",
       "Data_Scores_Acidity                0.758786                0.305512   \n",
       "Data_Scores_Body                   0.752955                0.241606   \n",
       "Data_Scores_Balance                1.000000                0.441438   \n",
       "Data_Scores_Uniformity             0.441438                1.000000   \n",
       "Data_Scores_Sweetness              0.284841                0.434928   \n",
       "Data_Scores_Moisture              -0.235669               -0.057012   \n",
       "\n",
       "                        Data_Scores_Sweetness  Data_Scores_Moisture  \n",
       "Data_Scores_Aroma                    0.074047             -0.148588  \n",
       "Data_Scores_Aftertaste               0.250585             -0.223684  \n",
       "Data_Scores_Acidity                  0.323370             -0.166047  \n",
       "Data_Scores_Body                     0.151394             -0.224135  \n",
       "Data_Scores_Balance                  0.284841             -0.235669  \n",
       "Data_Scores_Uniformity               0.434928             -0.057012  \n",
       "Data_Scores_Sweetness                1.000000             -0.011637  \n",
       "Data_Scores_Moisture                -0.011637              1.000000  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_explanatory.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be an issue with multicollinearity. Aftertaste and Aroma, Acidity and Aftertaste, Body and Aftertaste, Balance and Aftertaste, Balance and Acidity, Balance and Body are all multicollinear pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Non-Regularized Linear Regression Model\n",
    "\n",
    "### 2.1. Training the Model\n",
    "First, let's fit a non-regularized linear regression model using our training features matrix and target array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(training_explanatory,training_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Testing the Model\n",
    "\n",
    "Next, calculate the test R^2 of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446582317834092"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_model.score(test_explanatory, test_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LASSO Linear Regression Models\n",
    "\n",
    "\n",
    "### 3.1. Parameter Tuning\n",
    "\n",
    "Let's try to find the value of $\\lambda$ in a LASSO linear regression (that we will train with our training dataset) that *maximizes* the test $R^2$ value.\n",
    "\n",
    "1. In a for loop, iterate through a series of $\\lambda$ values that go from [0,0.005, 0.01, 0.015, 0.02,..., 0.5].\n",
    "2. For each value of $\\lambda$ do the following.\n",
    "    * Train a LASSO linear regression model with the training dataset and this given $\\lambda$.\n",
    "    * Calculate the test R^2 value for this LASSO linear regression model.\n",
    "    \n",
    "Your final result of this problem should include a *dataframe* that has two columns:\n",
    "* the $\\lambda$ value\n",
    "* the test R^2 that correspond to this $\\lambda$ value.\n",
    "\n",
    "*Hint: See the tutorial above for code suggestions).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabarishmogallapalli/miniconda3/lib/python3.11/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/sabarishmogallapalli/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sabarishmogallapalli/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e+00, tolerance: 2.544e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lambda Values</th>\n",
       "      <th>R^2 Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.844658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.841686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.837341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.832519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.827075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.480</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.485</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.490</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.495</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Lambda Values  R^2 Values\n",
       "0           0.000    0.844658\n",
       "1           0.005    0.841686\n",
       "2           0.010    0.837341\n",
       "3           0.015    0.832519\n",
       "4           0.020    0.827075\n",
       "..            ...         ...\n",
       "95          0.475   -0.009778\n",
       "96          0.480   -0.009778\n",
       "97          0.485   -0.009778\n",
       "98          0.490   -0.009778\n",
       "99          0.495   -0.009778\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "temp_list=[]\n",
    "for i in np.arange(0,0.5,0.005):\n",
    "    lasso_mod = Lasso(alpha = i, max_iter = 1000)\n",
    "    lasso_mod.fit(training_explanatory, training_response)\n",
    "    temp_list.append([i, lasso_mod.score(test_explanatory,test_response)])\n",
    "temp_list\n",
    "\n",
    "lambda_r2_df = pd.DataFrame(temp_list,columns=['Lambda Values', 'R^2 Values'])\n",
    "lambda_r2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Test R^2 and $\\lambda$ Relationship\n",
    "\n",
    "Plot the relationship between the $\\lambda$ values and the Test R^2 in a **line plot**.\n",
    "\n",
    "*Hint: Your code might look something like this.*\n",
    "\n",
    "`plt.plot(df_output['lambda'].values, df_output['test_r2'].values)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x132e8e1d0>]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lambda_r2_df['Lambda Values'].values, lambda_r2_df['R^2 Values'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Highest Test R^2\n",
    "\n",
    "Which of our fitted LASSO linear regression models do we think might perform the best when predicting coffee flavor for *new datasets*? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446582317834092"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_r2_df['R^2 Values'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first LASSO linear regression model will perform the best when predicting coffee flavor for new datasets. This is because it has the largest r^2 value which means it has the most predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. LASSO Linear Regression Model Improvment\n",
    "\n",
    "Did our best LASSO linear regression model perform better than our nonregularized linear regression model with respect to our primary research goal? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best LASSO linear regression model didn't perform better than our nonregularized linear regression model. It performed just as well. This can be seen from the r^2 values which are the same for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. LASSO Slope Interpretation\n",
    "\n",
    "#### 3.5.1. Slopes\n",
    "Display the slopes of your best LASSO linear regression model. Make sure your code output is able to indicate which slope corrresponds to which explanatory variable in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data_Scores_Aroma': 0.05760746208555128,\n",
       " 'Data_Scores_Aftertaste': 0.14782437750500296,\n",
       " 'Data_Scores_Acidity': 0.07450047557827688,\n",
       " 'Data_Scores_Body': 0.02112751347133229,\n",
       " 'Data_Scores_Balance': 0.03568005770036331,\n",
       " 'Data_Scores_Uniformity': 0.01993039655686342,\n",
       " 'Data_Scores_Sweetness': 0.0,\n",
       " 'Data_Scores_Moisture': 0.0}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=0.015)\n",
    "lasso_model.fit(training_explanatory,training_response)\n",
    "\n",
    "lasso_coeff = lasso_model.coef_\n",
    "\n",
    "expl_variables = training_explanatory.columns\n",
    "\n",
    "coeff_dict = {var: coef for var, coef in zip(expl_variables,lasso_coeff)}\n",
    "\n",
    "coeff_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2. Interpretation\n",
    "\n",
    "Are there any explanatory variables that this LASSO linear regression model is suggesting a.) do not bring enough predictive power to the model and b.) might be overfitting?\n",
    "\n",
    "If so, explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanatory variables with coefficients close to 0 (data_scores_aroma, data_scores_body, data_scores_balance, data_scores_uniformity, data_scores_sweetness, data_scores_moisture) don't bring enough predictive power to the model. The coefficient being close to 0 indicates that that variable is irrelevant to the model. Including these explanatory variables would be seen as overfitting to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. LASSO Linear Regression Multicollinearity\n",
    "\n",
    "Do the explanatory variables in your training features matrix that have non-zero slopes in your best LASSO linear regression model have an issue with multicollinearity? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Ridge Regression Models\n",
    "\n",
    "\n",
    "### 4.1. Parameter Tuning\n",
    "\n",
    "Let's try to find the value of $\\lambda$ in a linear ridge regression (that we will train with our training dataset) that *maximizes* the test $R^2$ value.\n",
    "\n",
    "1. In a for loop, iterate through a series of $\\lambda$ values that go from [0,1,2,3,..., 200].\n",
    "2. For each value of $\\lambda$ do the following.\n",
    "    * Train a linear ridge regression model with the training dataset and this given $\\lambda$.\n",
    "    * Calculate the test R^2 value for this linear ridge regression model.\n",
    "    \n",
    "Your final result of this problem should include a *dataframe* that has two columns:\n",
    "* the $\\lambda$ value\n",
    "* the test R^2 that correspond to this $\\lambda$ value.\n",
    "\n",
    "*Hint: See the tutorial above for code suggestions).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabarishmogallapalli/miniconda3/lib/python3.11/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/sabarishmogallapalli/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sabarishmogallapalli/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e+00, tolerance: 2.544e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lambda Values</th>\n",
       "      <th>R^2 Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.844658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>-0.009778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lambda Values  R^2 Values\n",
       "0                0    0.844658\n",
       "1                1   -0.009778\n",
       "2                2   -0.009778\n",
       "3                3   -0.009778\n",
       "4                4   -0.009778\n",
       "..             ...         ...\n",
       "195            195   -0.009778\n",
       "196            196   -0.009778\n",
       "197            197   -0.009778\n",
       "198            198   -0.009778\n",
       "199            199   -0.009778\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "temp_list=[]\n",
    "for i in np.arange(0,200,1):\n",
    "    lasso_mod = Lasso(alpha = i, max_iter = 1000)\n",
    "    lasso_mod.fit(training_explanatory, training_response)\n",
    "    temp_list.append([i, lasso_mod.score(test_explanatory,test_response)])\n",
    "temp_list\n",
    "\n",
    "lambda_r2_df2 = pd.DataFrame(temp_list,columns=['Lambda Values', 'R^2 Values'])\n",
    "lambda_r2_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Test R^2 and $\\lambda$ Relationship\n",
    "\n",
    "Plot the relationship between the $\\lambda$ values and the Test R^2 in a **line plot**.\n",
    "\n",
    "*Hint: Your code might look something like this.*\n",
    "\n",
    "`plt.plot(df_output['lambda'].values, df_output['test_r2'].values)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x130b9f850>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lambda_r2_df2['Lambda Values'].values, lambda_r2_df2['R^2 Values'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Highest Test R^2\n",
    "\n",
    "Which of our fitted linear ridge regression models do we think might perform the best when predicting coffee flavor for *new datasets*? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446582317834092"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_r2_df2['R^2 Values'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first LASSO linear regression model will perform the best when predicting coffee flavor for new datasets. This is because it has the largest r^2 value which means it has the most predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Linear Regression Model Improvment\n",
    "\n",
    "Did our best linear ridge regression model perform better than our nonregularized linear regression model and our best LASSO linear regression model with respect to our primary research goal? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best LASSO linear regression model didn't perform better than our nonregularized linear regression model. It performed just as well. This can be seen from the r^2 values which are the same for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Ridge Regression Slope Interpretation\n",
    "\n",
    "#### 4.5.1. Slopes\n",
    "Display the slopes of the following models in a dataframe. \n",
    "* Non-regularized linear regression model\n",
    "* Best LASSO linear regression model\n",
    "* Best linear ridge regression model\n",
    "\n",
    "Make sure your dataframe indicates what explanatory variable each slope corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=167, max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=167, max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=167, max_iter=10000)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridm = Ridge(alpha = 167, max_iter = 10000)\n",
    "ridm.fit(training_explanatory, training_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_slopes_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlin_reg_mod\u001b[39m\u001b[38;5;124m'\u001b[39m:linear_regression_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlasso_mod\u001b[39m\u001b[38;5;124m'\u001b[39m : lasso_model,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mridm\u001b[39m\u001b[38;5;124m'\u001b[39m:ridm}, index\u001b[38;5;241m=\u001b[39mx)\n\u001b[1;32m      2\u001b[0m df_slopes_2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "df_slopes_2 = pd.DataFrame({'lin_reg_mod':linear_regression_model, 'lasso_mod' : lasso_model,'ridm':ridm}, index=x)\n",
    "df_slopes_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2. Slope Reduction\n",
    "\n",
    "Create a new column in this dataframe which represents your:\n",
    "$\\frac{\\mbox{ridge regression slopes}}{\\mbox{corresponding nonregularized linear regression slopes}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_slopes_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[176], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_slopes_2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mridge/reg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_slopes_2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mridm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39mdf_slopes_2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_slopes_2' is not defined"
     ]
    }
   ],
   "source": [
    "df_slopes_2[\"ridge/reg\"] = df_slopes_2[\"ridm\"]/df_slopes_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 Interpretation\n",
    "\n",
    "Which regularization model (LASSO vs. ridge regression) is it easier to interpret which explanatory variables bring enough predictive power to the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO performs both feature selection and regularization. The non-zero slopes in the LASSO model directly show which variables are important, while the ones with zero coefficients are excluded. Lasso model is therefore easier to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.4. Slope Reduction Interpretation\n",
    "\n",
    "Which of our ridge regression slope absolute values decreased the most in comparison to it's corresponding original non-regularized linear regression model slope?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
